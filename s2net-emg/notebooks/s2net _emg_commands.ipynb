{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q03T6twRi_VG"
   },
   "source": [
    "# Spiking neural networks for EMG data streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40000,
     "status": "ok",
     "timestamp": 1647882372848,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "emABL544i_VJ",
    "outputId": "f963968b-c1b6-45e1-95d1-ee80a1bc63ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: librosa==0.9.1 in /usr/local/lib/python3.8/dist-packages (0.9.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.9.1) (1.6.2)\n",
      "Requirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.8/dist-packages (from librosa==0.9.1) (2.1.9)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.9.1) (0.2.2)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.9.1) (0.10.3.post1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.8/dist-packages (from librosa==0.9.1) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.45.1 in /home/magnapinna/.local/lib/python3.8/site-packages (from librosa==0.9.1) (0.53.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from librosa==0.9.1) (20.3)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.9.1) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa==0.9.1) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/magnapinna/.local/lib/python3.8/site-packages (from librosa==0.9.1) (1.21.4)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from librosa==0.9.1) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.45.1->librosa==0.9.1) (56.0.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/magnapinna/.local/lib/python3.8/site-packages (from numba>=0.45.1->librosa==0.9.1) (0.36.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/magnapinna/.local/lib/python3.8/site-packages (from pooch>=1.0->librosa==0.9.1) (2.27.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa==0.9.1) (1.4.4)\n",
      "Requirement already satisfied: six>=1.3 in /usr/lib/python3/dist-packages (from resampy>=0.2.2->librosa==0.9.1) (1.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.1) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa==0.9.1) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.1) (2.21)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (2.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/magnapinna/.local/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/magnapinna/.local/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (2019.11.28)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/magnapinna/.local/lib/python3.8/site-packages (from pandas) (1.21.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.21.4 in /home/magnapinna/.local/lib/python3.8/site-packages (1.21.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numba==0.53.0 in /home/magnapinna/.local/lib/python3.8/site-packages (0.53.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.53.0) (56.0.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/magnapinna/.local/lib/python3.8/site-packages (from numba==0.53.0) (1.21.4)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/magnapinna/.local/lib/python3.8/site-packages (from numba==0.53.0) (0.36.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.6.2)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /home/magnapinna/.local/lib/python3.8/site-packages (from scipy) (1.21.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/magnapinna/.local/lib/python3.8/site-packages (1.10.2+rocm4.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in /home/magnapinna/.local/lib/python3.8/site-packages (0.11.3+rocm4.2)\n",
      "Requirement already satisfied: torch==1.10.2 in /home/magnapinna/.local/lib/python3.8/site-packages (from torchvision) (1.10.2+rocm4.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (7.0.0)\n",
      "Requirement already satisfied: numpy in /home/magnapinna/.local/lib/python3.8/site-packages (from torchvision) (1.21.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.10.2->torchvision) (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.insert(0,\"/s2net-emg\")\n",
    "\n",
    "!pip install librosa==0.9.1\n",
    "!pip install pandas\n",
    "!pip install numpy==1.21.4\n",
    "!pip install numba==0.53.0\n",
    "!pip install scipy\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install matplotlib\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import time\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from utils import plot_spk_rec, plot_mem_rec\n",
    "from models import SNN, SpikingConv2DLayer, ReadoutLayer, SurrogateHeaviside, SpikingDenseLayer\n",
    "\n",
    "from data import EMGDataset, PSD, STFT, PSDNoDelta, NoFeatureExtraction, Rescale\n",
    "from optim import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1647882372852,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "AMaz_2VbW_z4"
   },
   "outputs": [],
   "source": [
    "# Different feature extraction functions\n",
    "# 0 - No feature extraction\n",
    "# 1 - PSD\n",
    "# 2 - STFT\n",
    "# 3 - PSDNoDelta\n",
    "MODE = 1\n",
    "# Load pretrained model?\n",
    "LOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1647882372854,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "EmmpVGsKi_VO"
   },
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqpEWSkSi_VQ"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1181,
     "status": "ok",
     "timestamp": 1647882374020,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "tctC0q75i_VQ",
    "outputId": "5c662c35-b7af-4620-b79c-08c6119a64e3"
   },
   "outputs": [],
   "source": [
    "train_data_root = \"../data/train\"\n",
    "test_data_root = \"../data/test\"\n",
    "\n",
    "training_words = os.listdir(train_data_root)\n",
    "training_words = [x for x in training_words if os.path.isdir(os.path.join(train_data_root,x))]\n",
    "training_words = [x for x in training_words if os.path.isdir(os.path.join(train_data_root,x)) if x[0] != \"_\" ]\n",
    "print(\"{} training words:\".format(len(training_words)))\n",
    "print(training_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1647882374021,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "m1VylLFwi_VS",
    "outputId": "b9ecc8b3-6113-4c05-8b5b-ecce5404637a"
   },
   "outputs": [],
   "source": [
    "testing_words = os.listdir(test_data_root)\n",
    "testing_words = [x for x in testing_words if os.path.isdir(os.path.join(train_data_root,x))]\n",
    "testing_words = [x for x in testing_words if os.path.isdir(os.path.join(train_data_root,x)) \n",
    "                 if x[0] != \"_\"]\n",
    "print(\"{} testing words:\".format(len(testing_words)))\n",
    "if len(testing_words) != len(training_words):\n",
    "    raise ValueError(\"Mismathed data\")\n",
    "print(testing_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1647882374022,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "o1Vrl2aYi_VU",
    "outputId": "83be30ac-d911-4018-f1e4-73c52f7070e6"
   },
   "outputs": [],
   "source": [
    "# Using labels from datasets\n",
    "lb = sorted(testing_words)\n",
    "label_dct = {lb[i]: i for i in range(len(lb))}\n",
    "if len(testing_words) != len(label_dct.keys()):\n",
    "    raise ValueError(\"Mismathed data\")\n",
    "print(\"label_dct:\")\n",
    "print(label_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1647882374023,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "4FS-jJ8mi_VW"
   },
   "outputs": [],
   "source": [
    "sr = 150\n",
    "size = 150\n",
    "n_fft = size\n",
    "hop_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1647882374024,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "6BWlSwS6i_Vb"
   },
   "outputs": [],
   "source": [
    "stft = STFT(n_fft, hop_length)\n",
    "psd = PSD(sr, n_fft)\n",
    "psdnodelta = PSDNoDelta(sr, n_fft)\n",
    "nfe = NoFeatureExtraction()\n",
    "\n",
    "rescale = Rescale()\n",
    "\n",
    "if MODE == 0:\n",
    "    transform = torchvision.transforms.Compose([nfe, rescale])\n",
    "    in_chan = 1\n",
    "    in_sh = 8\n",
    "elif MODE == 1:\n",
    "    transform = torchvision.transforms.Compose([psd, rescale])\n",
    "    in_chan = 2\n",
    "    in_sh = 8\n",
    "elif MODE == 2:\n",
    "    transform = torchvision.transforms.Compose([stft, rescale])\n",
    "    in_chan = 8\n",
    "    in_sh = 52\n",
    "elif MODE == 3:\n",
    "    transform = torchvision.transforms.Compose([psdnodelta, rescale])\n",
    "    in_chan = 1\n",
    "    in_sh = 8\n",
    "else:\n",
    "    print(\"Incorect mode, using no transform\")\n",
    "    transform = torchvision.transforms.Compose([nfs, rescale])\n",
    "    in_chan = 1\n",
    "    in_sh = 8\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    \n",
    "    X_batch = np.array([d[0] for d in data])\n",
    "    std = X_batch.std(axis=(0,3), keepdims=True)\n",
    "    X_batch = torch.tensor(X_batch/std)\n",
    "    \n",
    "    y_batch = torch.tensor([d[1] for d in data])\n",
    "    \n",
    "    return X_batch, y_batch \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23082,
     "status": "ok",
     "timestamp": 1647882397089,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "-NJC2AVVi_Vd"
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_dataset = EMGDataset(train_data_root, label_dct, transform = transform, mode=\"train\", max_nb_per_class=None)\n",
    "train_sampler = torch.utils.data.WeightedRandomSampler(train_dataset.weights,len(train_dataset.weights))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, sampler=train_sampler, collate_fn=collate_fn)\n",
    "\n",
    "test_dataset = EMGDataset(test_data_root, label_dct, transform = transform, mode=\"test\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dkh6-tHdi_Vf"
   },
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12504,
     "status": "ok",
     "timestamp": 1647882409535,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "AbbYxEkZi_Vf",
    "outputId": "7c30aac7-0437-42b2-b9d7-e10e1e4e028b"
   },
   "outputs": [],
   "source": [
    "spike_fn = SurrogateHeaviside.apply\n",
    "\n",
    "w_init_std = 0.15\n",
    "w_init_mean = 0.\n",
    "\n",
    "w_init_std = 0.15\n",
    "w_init_mean = 0.\n",
    "\n",
    "\n",
    "layers = []\n",
    "in_channels = in_chan\n",
    "out_channels = 64\n",
    "kernel_size = (4,3)\n",
    "dilation = (1,1)\n",
    "input_shape = in_sh\n",
    "output_shape = input_shape # padding mode is \"same\"\n",
    "layers.append(SpikingConv2DLayer(input_shape, output_shape,\n",
    "                 in_channels, out_channels, kernel_size, dilation,\n",
    "                 spike_fn, w_init_mean=w_init_mean, w_init_std=w_init_std, recurrent=False,\n",
    "                               lateral_connections=True))\n",
    "\n",
    "in_channels = out_channels\n",
    "out_channels = 64\n",
    "kernel_size = (4,3)\n",
    "dilation = (4,3)\n",
    "input_shape = output_shape\n",
    "output_shape = input_shape # padding mode is \"same\"\n",
    "layers.append(SpikingConv2DLayer(input_shape, output_shape,\n",
    "                 in_channels, out_channels, kernel_size, dilation,\n",
    "                 spike_fn, w_init_mean=w_init_mean, w_init_std=w_init_std, recurrent=False,\n",
    "                              lateral_connections=True))\n",
    "\n",
    "in_channels = out_channels\n",
    "out_channels = 64\n",
    "kernel_size = (4,3)\n",
    "dilation = (4,3)\n",
    "input_shape = output_shape\n",
    "output_shape = input_shape # padding mode is \"same\"\n",
    "layers.append(SpikingConv2DLayer(input_shape, output_shape,\n",
    "                 in_channels, out_channels, kernel_size, dilation,\n",
    "                 spike_fn, w_init_mean=w_init_mean, w_init_std=w_init_std, recurrent=False,\n",
    "                               lateral_connections=True, flatten_output=True))\n",
    "\n",
    "# previous layer output has been flattened\n",
    "input_shape = output_shape*out_channels\n",
    "output_shape = 10\n",
    "time_reduction=\"mean\" #mean or max\n",
    "layers.append(ReadoutLayer(input_shape, output_shape,\n",
    "                 w_init_mean=w_init_mean, w_init_std=w_init_std, time_reduction=time_reduction))\n",
    "\n",
    "snn = SNN(layers).to(device, dtype)\n",
    "\n",
    "X_batch, _ = next(iter(train_dataloader))\n",
    "X_batch = X_batch.to(device, dtype)\n",
    "snn(X_batch)\n",
    "\n",
    "for i,l in enumerate(snn.layers):\n",
    "    if isinstance(l, SpikingDenseLayer) or isinstance(l, SpikingConv2DLayer):\n",
    "        print(\"Layer {}: average number of spikes={:.4f}\".format(i,l.spk_rec_hist.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1647882409537,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "RhxqAQo5i_VN"
   },
   "outputs": [],
   "source": [
    "#LOADING MODEL\n",
    "if LOAD:\n",
    "    if MODE == 1:\n",
    "        snn.load_state_dict(torch.load(\"../saved/modeldictPSD.pt\", map_location=device))\n",
    "    elif MODE == 2:\n",
    "        snn.load_state_dict(torch.load(\"../saved/modeldictSTFT.pt\", map_location=device))\n",
    "    elif MODE == 3:\n",
    "        snn.load_state_dict(torch.load(\"../saved/modeldictPSDNoDelta.pt\", map_location=device))  \n",
    "    else:\n",
    "        snn.load_state_dict(torch.load(\"../saved/modeldictNOFE.pt\", map_location=device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6E_0E5yi_Vh"
   },
   "source": [
    "# Training and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1B2oW4_rvlA9WmyxOuz0aMLY52K66TVZd"
    },
    "executionInfo": {
     "elapsed": 30730,
     "status": "ok",
     "timestamp": 1647882440255,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "OOsdGB1xi_Vh",
    "outputId": "5c7a911d-7f92-401a-dab2-47cbca0d7a44"
   },
   "outputs": [],
   "source": [
    "nb_plt = 9\n",
    "\n",
    "batch_idx = np.random.choice(batch_size, nb_plt, replace=False)\n",
    "\n",
    "# Plotting spike trains or membrane potential\n",
    "for i,l in enumerate(snn.layers):\n",
    "    \n",
    "    if isinstance(l, SpikingDenseLayer):\n",
    "        spk_rec = l.spk_rec_hist\n",
    "        plot_spk_rec(spk_rec, idx=batch_idx)\n",
    "    elif isinstance(l, SpikingConv2DLayer):\n",
    "        spk_rec = l.spk_rec_hist\n",
    "        plot_spk_rec(spk_rec.sum(1), idx=batch_idx)\n",
    "    else:\n",
    "        mem_rec = l.mem_rec_hist\n",
    "        plot_mem_rec(mem_rec, batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1647882440257,
     "user": {
      "displayName": "Mary Cowell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17271665796611109344"
     },
     "user_tz": -180
    },
    "id": "z8kCom-Yi_Vi"
   },
   "outputs": [],
   "source": [
    "def train(model, params, optimizer, train_dataloader, reg_loss_coef, nb_epochs, scheduler=None, warmup_epochs=0):\n",
    "    \n",
    "    log_softmax_fn = torch.nn.LogSoftmax(dim=1)\n",
    "    loss_fn = torch.nn.NLLLoss()\n",
    "    \n",
    "    if warmup_epochs > 0:\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] /= len(train_dataloader)*warmup_epochs\n",
    "        warmup_itr = 1\n",
    "    \n",
    "    hist = {'loss':[]}\n",
    "    for e in range(nb_epochs):\n",
    "        local_loss = []\n",
    "        reg_loss = [[] for _ in range(len(model.layers)-1)]\n",
    "        \n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "\n",
    "            x_batch = x_batch.to(device, dtype)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            output, loss_seq = model(x_batch)\n",
    "            log_p_y = log_softmax_fn(output)\n",
    "            loss_val = loss_fn(log_p_y, y_batch)\n",
    "            local_loss.append(loss_val.item())\n",
    "\n",
    "            for i,loss in enumerate(loss_seq[:-1]):\n",
    "                reg_loss_val = reg_loss_coef*loss*(i+1)/len(loss_seq[:-1])\n",
    "                loss_val += reg_loss_val\n",
    "                reg_loss[i].append(reg_loss_val.item())\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            torch.nn.utils.clip_grad_value_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            model.clamp()\n",
    "\n",
    "            if e < warmup_epochs:\n",
    "                for g in optimizer.param_groups:\n",
    "                    g['lr'] *= (warmup_itr+1)/(warmup_itr)\n",
    "                warmup_itr += 1\n",
    "                \n",
    "                \n",
    "        if scheduler is not None and e >= warmup_epochs:\n",
    "            scheduler.step()\n",
    "        \n",
    "        mean_loss = np.mean(local_loss)\n",
    "        hist['loss'].append(mean_loss)\n",
    "        print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        \n",
    "        for i,loss in enumerate(reg_loss):\n",
    "            mean_reg_loss = np.mean(loss)\n",
    "            print(\"Layer %i: reg loss=%.5f\"%(i,mean_reg_loss))\n",
    "            \n",
    "        for i,l in enumerate(snn.layers[:-1]):\n",
    "            print(\"Layer {}: average number of spikes={:.4f}\".format(i,l.spk_rec_hist.mean()))\n",
    "        \n",
    "\n",
    "    return hist\n",
    "        \n",
    "def compute_classification_accuracy(model, dataloader):\n",
    "    accs = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "\n",
    "            x_batch = x_batch.to(device, dtype)\n",
    "            y_batch = y_batch.to(device)\n",
    "            output, _ = model(x_batch)\n",
    "            _,am=torch.max(output,1) # argmax over output units\n",
    "            tmp = np.mean((y_batch==am).detach().cpu().numpy()) # compare to labels\n",
    "            accs.append(tmp)\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2kVnXwxi_Vk",
    "outputId": "48139598-6c84-4cd7-8157-815aff799476",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if LOAD == False:\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-5\n",
    "    reg_loss_coef = 0.1\n",
    "    nb_epochs = 10\n",
    "    warmup_epochs = 1\n",
    "\n",
    "    params = [{'params':l.w, 'lr':lr, \"weight_decay\":weight_decay } for i,l in enumerate(snn.layers)]\n",
    "    params += [{'params':l.v, 'lr':lr, \"weight_decay\":weight_decay} for i,l in enumerate(snn.layers[:-1]) if l.recurrent]\n",
    "    params += [{'params':l.b, 'lr':lr} for i,l in enumerate(snn.layers)]\n",
    "    if snn.layers[-1].time_reduction == \"mean\":\n",
    "        params += [{'params':l.beta, 'lr':lr} for i,l in enumerate(snn.layers[:-1])]\n",
    "    elif snn.layers[-1].time_reduction == \"max\":\n",
    "        params += [{'params':l.beta, 'lr':lr} for i,l in enumerate(snn.layers)]\n",
    "    else:\n",
    "        raise ValueError(\"Readout time recution should be 'max' or 'mean'\")\n",
    "    \n",
    "    optimizer = RAdam(params)\n",
    " \n",
    "    gamma = 0.85\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma, last_epoch=-1)\n",
    "\n",
    "    hist = train(snn, params, optimizer, train_dataloader, reg_loss_coef, nb_epochs=nb_epochs,\n",
    "                    scheduler=scheduler, warmup_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgOQxclyi_Vl"
   },
   "outputs": [],
   "source": [
    "test_accuracy = compute_classification_accuracy(snn, test_dataloader)\n",
    "print(\"Test accuracy=%.3f\"%(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCYBvoc4i_Vl"
   },
   "outputs": [],
   "source": [
    "snn(X_batch)\n",
    "\n",
    "# Plotting spike trains or membrane potential\n",
    "for i,l in enumerate(snn.layers):\n",
    "    \n",
    "    if isinstance(l, SpikingDenseLayer):\n",
    "        print(\"Layer {}: average number of spikes={:.4f}\".format(i,l.spk_rec_hist.mean()))\n",
    "        spk_rec = l.spk_rec_hist\n",
    "        plot_spk_rec(spk_rec, idx=batch_idx)\n",
    "    elif isinstance(l, SpikingConv2DLayer):\n",
    "        print(\"Layer {}: average number of spikes={:.4f}\".format(i,l.spk_rec_hist.mean()))\n",
    "        spk_rec = l.spk_rec_hist\n",
    "        plot_spk_rec(spk_rec.sum(1), idx=batch_idx)\n",
    "    else:\n",
    "        mem_rec = l.mem_rec_hist\n",
    "        plot_mem_rec(mem_rec, batch_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SP35krX9i_Vl"
   },
   "outputs": [],
   "source": [
    "from streamload import EMGStream, PSD, STFT, PSDNoDelta, NoFeatureExtraction, Rescale\n",
    "\n",
    "def compute_classification_accuracy(model, dataloader):\n",
    "    accs = []\n",
    "    cnt = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "\n",
    "            x_batch = x_batch.to(device, dtype)\n",
    "            y_batch = y_batch.to(device)\n",
    "            output, _ = model(x_batch)\n",
    "            _,am=torch.max(output,1) # argmax over output units\n",
    "            tmp = np.mean((y_batch==am).detach().cpu().numpy()) # compare to labels\n",
    "            accs.append(tmp)\n",
    "\n",
    "            if cnt%15 == 0:\n",
    "                print(\"Estimation: \", tmp, \"SNN output: \", am.item(), \"Label: \", y_batch.item())\n",
    "                print(\"Batches estimated: \", cnt)\n",
    "                print(\"Avg accuracy: %0.3f\"%np.mean(accs))\n",
    "            cnt+=1\n",
    "\n",
    "    return np.mean(accs)\n",
    "\n",
    "fn = \"../raw/2_raw_data_1.txt\"\n",
    "bat_size = 15\n",
    "buff_size = 150  # a multiple of bat_size\n",
    "\n",
    "stft = STFT(n_fft, hop_length)\n",
    "psd = PSD(sr, n_fft)\n",
    "psdnodelta = PSDNoDelta(sr, n_fft)\n",
    "nfe = NoFeatureExtraction()\n",
    "\n",
    "rescale = Rescale()\n",
    "\n",
    "if MODE == 0:\n",
    "    transform = torchvision.transforms.Compose([nfe, rescale])\n",
    "    in_chan = 1\n",
    "    in_sh = 8\n",
    "elif MODE == 1:\n",
    "    transform = torchvision.transforms.Compose([psd, rescale])\n",
    "    in_chan = 2\n",
    "    in_sh = 8\n",
    "elif MODE == 2:\n",
    "    transform = torchvision.transforms.Compose([stft, rescale])\n",
    "    in_chan = 8\n",
    "    in_sh = 52\n",
    "elif MODE == 3:\n",
    "    transform = torchvision.transforms.Compose([psdnodelta, rescale])\n",
    "    in_chan = 1\n",
    "    in_sh = 8\n",
    "else:\n",
    "    print(\"Incorect mode, using no transform\")\n",
    "    transform = torchvision.transforms.Compose([nfs, rescale])\n",
    "    in_chan = 1\n",
    "    in_sh = 8\n",
    "\n",
    "\n",
    "\n",
    "stream_loader = EMGStream(fn, bat_size, buff_size, transform=transform, shuffle=False)\n",
    "test_accuracy = compute_classification_accuracy(snn, stream_loader)\n",
    "print(\"Test accuracy=%.3f\"%(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "s2net _emg_commands.ipynb",
   "provenance": [
    {
     "file_id": "1r6KsxDGszi8A9OAGFXd1FHOFT-GVdwdv",
     "timestamp": 1645035126013
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
